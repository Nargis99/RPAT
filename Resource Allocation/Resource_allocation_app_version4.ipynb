{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyodbc\n",
    "# !pip install flask\n",
    "# !pip install openpyxl\n",
    "# !pip install excel2img\n",
    "# !pip install numpy\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nasreenn\\AppData\\Local\\Temp\\ipykernel_22312\\1102068466.py:22: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  from distutils.log import debug\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "import sys\n",
    "import pyodbc\n",
    "import openpyxl\n",
    "import warnings\n",
    "import pythoncom\n",
    "import shutil\n",
    "import tempfile\n",
    "import time as t\n",
    "import time\n",
    "import datetime\n",
    "import excel2img\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import * \n",
    "import datetime as dt\n",
    "from datetime import datetime, time\n",
    "from datetime import datetime\n",
    "from pandas import Timestamp\n",
    "from fileinput import filename\n",
    "from distutils.log import debug\n",
    "import win32com.client as win32\n",
    "from openpyxl.styles import Font\n",
    "warnings.filterwarnings('ignore')\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.styles.colors import Color\n",
    "from openpyxl.drawing.image import Image\n",
    "from werkzeug.utils import secure_filename\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get current directory\n",
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\nasreenn\\\\Documents\\\\CDM Projects\\\\Resource Allocation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only excel file is allowed\n",
    "ALLOWED_EXTENSIONS = {'xlsx'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To initate the app\n",
    "app = Flask(__name__)\n",
    "# To activate the upload folder\n",
    "app.config['UPLOAD_FOLDER'] = current_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route 1: For Index page\n",
    "@app.route('/')  \n",
    "def main():  \n",
    "    return render_template(\"index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check the file extension\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: To get details like - user-email-id, file\n",
    "@app.route('/success', methods=['GET', 'POST'])\n",
    "def success():\n",
    "    error = None;\n",
    "    if request.method == 'POST':\n",
    "        if 'file' not in request.files:\n",
    "            flash('No file uploaded')\n",
    "        file = request.files['file']\n",
    "        if file.filename == '':\n",
    "            error = \"No file selected\"\n",
    "        if file and not allowed_file(file.filename):\n",
    "            error = \"File extension should be .xlsx\"\n",
    "        else:\n",
    "            email_u = request.form.get(\"email\")\n",
    "            email_u=email_u.lower()\n",
    "            list_of_email=['maxinn@cdmsmith.com',\n",
    "            'kalariarb@cdmsmith.com',\n",
    "            'sachinc@cdmsmith.com',\n",
    "            'dwivedivt@cdmsmith.com',\n",
    "            'belcherca@cdmsmith.com',\n",
    "            'raufk@cdmsmith.com',\n",
    "            'martinesea@cdmsmith.com',\n",
    "            'nejadaa@cdmsmith.com',\n",
    "            'singhap@cdmsmith.com',\n",
    "            'patildv@cdmsmith.com',\n",
    "            'goycolj@cdmsmith.com',\n",
    "            'sutterd@cdmsmith.com',\n",
    "            'dattas@cdmsmith.com',\n",
    "            'patilvv@cdmsmith.com',\n",
    "            'senguptab@cdmsmith.com',\n",
    "            'acharyyas@cdmsmith.com',\n",
    "            'dubeya@cdmsmith.com',\n",
    "            'joaninojj@cdmsmith.com',\n",
    "            'rangarajr@cdmsmith.com',\n",
    "            'kwonoe@cdmsmith.com',\n",
    "            'suhasc@cdmsmith.com',\n",
    "            'abhishekv@cdmsmith.com',\n",
    "            'salousfh@cdmsmith.com',\n",
    "            'mishraa@cdmsmith.com',\n",
    "            'rajath@cdmsmith.com',\n",
    "            'niemiecme@cdmsmith.com',\n",
    "            'tevarnd@cdmsmith.com',\n",
    "            'hollandbm@cdmsmith.com',\n",
    "            'dunbarcj@cdmsmith.com',\n",
    "            'patilpa@cdmsmith.com',\n",
    "            'melendezmunozev@cdmsmith.com',\n",
    "            'warudkarpa@cdmsmith.com',\n",
    "            'kumarip@cdmsmith.com',\n",
    "            'niranjanar@cdmsmith.com',\n",
    "            'MilodovskaiaI@cdmsmith.com',\n",
    "            'shahbaza@cdmsmith.com',\n",
    "            'akhils@cdmsmith.com',\n",
    "            'chaleilam@cdmsmith.com',\n",
    "            'alamurikr@cdmsmith.com',\n",
    "            'manishas@cdmsmith.com',\n",
    "            'sahill@cdmsmith.com',\n",
    "            'chandrakara@cdmsmith.com',\n",
    "            'bhatiat@cdmsmith.com',\n",
    "            'paulvs@cdmsmith.com',\n",
    "            'poddara@cdmsmith.com',\n",
    "            'sinhas@cdmsmith.com',\n",
    "            'karthikjm@cdmsmith.com',\n",
    "            'prashantkk@cdmsmith.com',\n",
    "            'shelarsv@cdmsmith.com',\n",
    "            'tripathij@cdmsmith.com',\n",
    "            'bodkhesp@cdmsmith.com',\n",
    "            'remediosjh@cdmsmith.com',\n",
    "            'campbellg@cdmsmith.com',\n",
    "            'dagaa@cdmsmith.com',\n",
    "            'bhandarip@cdmsmith.com',\n",
    "            'nasreenn@cdmsmith.com',\n",
    "            'gouthams@cdmsmith.com',\n",
    "            'singhg@cdmsmith.com']\n",
    "            if email_u in list_of_email: \n",
    "                global email_f\n",
    "                email_f = email_u.split('@')[0]\n",
    "                filename2=(file.filename).split('.xlsx')[0]+'-'+email_f+'.xlsx'\n",
    "                filename = secure_filename(filename2)\n",
    "                file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "                return redirect(url_for('external', name=filename, email=email_f, u_email=email_u))\n",
    "            else:\n",
    "                error='Email is not correct'\n",
    "        return  render_template('index.html',error=error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App\n",
    "@app.route('/external/<name>/<email>/<u_email>', methods=['GET', 'POST']) \n",
    "def external(name,email,u_email):\n",
    "    global temp_folder\n",
    "    temp_folder=current_directory+'\\\\reports'\n",
    "    now = t.time()\n",
    "    for f in os.listdir(temp_folder):\n",
    "        f = os.path.join(temp_folder, f)\n",
    "        if os.stat(f).st_mtime < now - 1 * 86400:\n",
    "             if os.path.isfile(f):\n",
    "                os.remove(os.path.join(temp_folder, f))\n",
    "    DB = {'servername': 'AW02PSQLC007',\n",
    "    'database': 'india_gtsg'}\n",
    "    conn = pyodbc.connect('DRIVER={SQL Server}; SERVER=' + DB['servername'] + ';DATABASE=' + DB['database'] + ';Trusted_Connection=yes')\n",
    "    rft_report = pd.read_sql_query('''SELECT * FROM [India_gtsg].[dbo].[RFT_P6]''', conn)\n",
    "    ut = pd.read_sql_query('''SELECT * FROM [India_gtsg].[dbo].[UT]''', conn)\n",
    "    calendar = pd.read_sql_query('''SELECT * FROM [india_gtsg].[dbo].[calendar]''', conn)\n",
    "#     data = pd.read_excel('{}'.format(name), sheet_name = 'P6')\n",
    "    # Try reading the Excel file with sheet_name 'P6'\n",
    "    try:\n",
    "        data = pd.read_excel('{}'.format(name), sheet_name='P6')\n",
    "    except:\n",
    "    # If the 'P6' sheet is not found, read the 'Sheet1' sheet\n",
    "        data = pd.read_excel('{}'.format(name), sheet_name='Sheet1')\n",
    "    rft_report = rft_report.drop(['Month-Year', 'Utilization_Target_percent'], axis = 1)\n",
    "    \n",
    "    cursor = conn.cursor()    \n",
    "    SQLCommand = (\"INSERT INTO users(email) VALUES (?)\")  \n",
    "    Values = [u_email]   \n",
    "    cursor.execute(SQLCommand,Values)     \n",
    "    conn.commit()\n",
    "\n",
    "    # Popping the column to change the position\n",
    "    cll1 = rft_report.pop('Utilization_Target')\n",
    "    cll2 = rft_report.pop('Employee_code')\n",
    "    cll3 = rft_report.pop('Resource_Name')\n",
    "    cll4 = rft_report.pop('Project Number')\n",
    "\n",
    "    # Placing the pop up column at first\n",
    "    rft_report.insert(2, 'Utilization_Target', cll1)\n",
    "    # Placing the pop up column at first\n",
    "    rft_report.insert(2, 'Employee_code', cll2)\n",
    "    # Placing the pop up column at first\n",
    "    rft_report.insert(2, 'Resource_Name', cll3)\n",
    "    # Placing the pop up column at first\n",
    "    rft_report.insert(2, 'Project Number', cll4)\n",
    "\n",
    "    # To replace dash (-) & NaN with Zero (0)\n",
    "    except_columns = ['Project', 'Resource (Utilization Target %)/Job Code', 'Project Number', 'Resource_Name', 'Employee_code', 'Utilization_Target']\n",
    "    for column in rft_report.columns:\n",
    "        if column not in except_columns:\n",
    "            rft_report[column] = rft_report[column].replace('-', 0)\n",
    "            rft_report[column] = rft_report[column].replace(np.NaN, 0)\n",
    "\n",
    "    # To change the dtypes of columns\n",
    "    except_columns = ['Project', 'Resource (Utilization Target %)/Job Code', 'Project Number', 'Resource_Name', 'Employee_code', 'Utilization_Target']\n",
    "    for column in rft_report.columns:\n",
    "        if column not in except_columns:\n",
    "            rft_report[column] = pd.to_numeric(rft_report[column], errors = 'coerce')\n",
    "\n",
    "    # Remove extra space\n",
    "    rft_report['Employee_code'] = rft_report['Employee_code'].apply(str.strip)\n",
    "    \n",
    "    # Dropping unwanted columns\n",
    "    data1 = data.drop(['Activity Name', 'Curve', 'Spreadsheet Field', 'Remaining Units'], axis = 1)\n",
    "\n",
    "    #changing the format of date and adding it in a new column\n",
    "    calendar['Month_Year'] = calendar['GL Period'].apply(lambda x: x.strftime('%b-%y')) \n",
    "    # Extracting Month columns \n",
    "    data2 = data1.iloc[:, 1:]\n",
    "\n",
    "    x = data2.columns[0]\n",
    "    x2 = x.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    x3 = x2.replace(' 00:00:00', '')\n",
    "    # Rename a column using the .rename() method\n",
    "    data2.rename(columns={x2: x3}, inplace=True)\n",
    "\n",
    "    # Fix time frame according to RFT (18 months)\n",
    "\n",
    "    # To get currentatime\n",
    "    current_date = dt.datetime.now()\n",
    "    # current_date = '2023-10-29'\n",
    "    # Select dates less than current time\n",
    "    current_date_less = calendar[calendar['W/E Date'] <= current_date]\n",
    "    # Convert the datatype\n",
    "    current_date_less['W/E Date'] = current_date_less['W/E Date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    # Select last date which is just less than current date - start date\n",
    "    start_d = current_date_less.tail(1)\n",
    "\n",
    "    # Store start date in a list\n",
    "    start = start_d['GL Period'].tolist()\n",
    "    start_dt = start[0]\n",
    "    varr = start_dt.strftime('%Y-%m-%d')\n",
    "    start_date = varr.replace(' 00:00:00', '')\n",
    "\n",
    "    # Convert the string to a datetime object\n",
    "    start_date = dt.datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "\n",
    "    # Add 18 months using relativedelta\n",
    "    end_date = start_date + relativedelta(months=17)\n",
    "\n",
    "    # Convert the future date back to a string if needed\n",
    "    end_date = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    var1 = data2.columns[0]\n",
    "    var2 = var1.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Specify the format of the date string\n",
    "    date_format = '%Y-%m-%d'  # This format corresponds to 'YYYY-MM-DD'\n",
    "\n",
    "    # Convert the string to a datetime.date object\n",
    "    date_obj = datetime.strptime(var2, date_format).date()\n",
    "    end_date = datetime.strptime(end_date, date_format).date()\n",
    "\n",
    "    # Create a time object with the desired time (e.g., midnight)\n",
    "    time_obj = time(0, 0)  # This represents 00:00:00 (midnight)\n",
    "\n",
    "    # Combine the date and time to create a datetime.datetime object\n",
    "    datetime_obj = datetime.combine(date_obj, time_obj)\n",
    "    datetime_start = datetime.combine(start_date, time_obj)\n",
    "    datetime_end = datetime.combine(end_date, time_obj)\n",
    "\n",
    "    if datetime_start != datetime_obj:\n",
    "        if datetime_start < datetime_obj:\n",
    "            # Selecting columns mentioned in P6\n",
    "            calendar = calendar[calendar['W/E Date'].isin(data2.columns)] \n",
    "            calender = calendar[calendar['W/E Date'] >= datetime_obj]\n",
    "            # Reindexing\n",
    "            calender = calender.reset_index(drop = True)\n",
    "            # Select rows within the date range\n",
    "            final_calender = calender[(calender['W/E Date'] >= datetime_obj) & (calender['W/E Date'] <= datetime_end)]\n",
    "            column_list = final_calender['W/E Date'].tolist()\n",
    "            # Convert the list of timestamps to a list of strings\n",
    "            col_list = [timestamp.strftime('%Y-%m-%d') for timestamp in column_list]\n",
    "            data2 = data2[col_list]\n",
    "            #extracting all month-year values\n",
    "            month = final_calender['Month_Year'].values\n",
    "            data5 = data2.set_axis(month, axis = 'columns')\n",
    "        else: \n",
    "            # Selecting columns mentioned in P6\n",
    "            calendar = calendar[calendar['W/E Date'].isin(data2.columns)] \n",
    "            calender = calendar[calendar['GL Period'] >= datetime_start]\n",
    "            # Reindexing\n",
    "            calender = calender.reset_index(drop = True)\n",
    "            # Select rows within the date range\n",
    "            final_calender = calender[(calender['GL Period'] >= datetime_start) & (calender['GL Period'] <= datetime_end)]\n",
    "            column_list = final_calender['W/E Date'].tolist()\n",
    "            data2 = data2[column_list]\n",
    "            #extracting all month-year values\n",
    "            month = final_calender['Month_Year'].values\n",
    "            data5 = data2.set_axis(month, axis = 'columns')\n",
    "    else: \n",
    "        # Selecting columns mentioned in P6\n",
    "        calendar = calendar[calendar['W/E Date'].isin(data2.columns)] \n",
    "        calender = calendar[calendar['W/E Date'] >= datetime_obj]\n",
    "        # Reindexing\n",
    "        calender = calender.reset_index(drop = True)\n",
    "        # Select rows within the date range\n",
    "        final_calender = calender[(calender['W/E Date'] >= datetime_obj) & (calender['W/E Date'] <= datetime_end)]\n",
    "        column_list = final_calÃ¨nder['W/E Date'].tolist()\n",
    "        data2 = data2[column_list]\n",
    "        #extracting all month-year values\n",
    "        month = final_calender['Month_Year'].values\n",
    "        data5 = data2.set_axis(month, axis = 'columns')\n",
    "    \n",
    "    # Joining df with p_six\n",
    "    data5.insert(loc = 0, column = 'Activity ID', value = data['Activity ID'])\n",
    "\n",
    "    # Extracting rows with 'Employee Number'\n",
    "    code = data5[data5['Activity ID'].str.contains(\"Employee\")]\n",
    "    # Creating new column named 'Resource Name' by replacing Resource name from col 'Activity ID'\n",
    "    code['Employee Number'] = code['Activity ID'].str.replace('Employee Number: ', '')\n",
    "\n",
    "    # Dropping unwanted columns\n",
    "    dataset = code.drop('Activity ID', axis = 1)\n",
    "\n",
    "    # Popping the column to change the position\n",
    "    val1 = dataset.pop('Employee Number')\n",
    "\n",
    "    # Placing the pop up column at first\n",
    "    dataset.insert(0, 'Employee Number', val1)\n",
    "\n",
    "    # Reseting Index\n",
    "    data6 = dataset.reset_index()\n",
    "\n",
    "    # Dropping unwanted columns\n",
    "    data7 = data6.drop(['index'], axis = 1)\n",
    "\n",
    "    # Changing column name '0' ---> 'Project Number'\n",
    "    data7.rename(columns = {'Employee Number': 'Employee_code'}, inplace = True)\n",
    "\n",
    "    # Remove extra space\n",
    "    data7['Employee_code'] = data7['Employee_code'].apply(str.strip)\n",
    "\n",
    "    # Extracting rows with 'WBS'\n",
    "    wbs = data5[data5['Activity ID'].str.contains(\"WBS: \")]\n",
    "\n",
    "    # Extracting numbers from main column\n",
    "    wbs['num'] = wbs['Activity ID'].str.findall(r'[0-9]+')   #output: [285241, 01, 01], want only oth index i.e., project number\n",
    "\n",
    "    # Removing brackets from each row\n",
    "    wbs[\"Project Number\"] = wbs[\"num\"].str.get(0)\n",
    "\n",
    "    # Project Number in p6\n",
    "    global pn_list\n",
    "    pn_list = list(wbs['Project Number'].unique())\n",
    "        # List of unique Resource Name in p6 data\n",
    "    unique_resource = list(data7['Employee_code'].unique())\n",
    "    unique_resource = [i.strip() for i in unique_resource]\n",
    "    \n",
    "    # Extracting rows with 'Resource Name'\n",
    "    pattern = 'Resource|Employee'\n",
    "\n",
    "    code = data5[data5['Activity ID'].str.contains(pattern)]\n",
    "\n",
    "    # Creating new column named 'Resource Name' by replacing Resource name from col 'Activity ID'\n",
    "    code['Info'] = code['Activity ID'].str.replace('Employee Number:', '')\n",
    "    code['Info'] = code['Info'].str.replace('Resource Name: ', '')\n",
    "\n",
    "    # Dropping unwanted columns\n",
    "    codeset = code.drop('Activity ID', axis = 1)\n",
    "    codeset = codeset.reset_index()\n",
    "\n",
    "    codeset = codeset.drop(['index'], axis = 1)\n",
    "\n",
    "    ll2 = codeset.pop('Info')\n",
    "\n",
    "    # Placing the pop up column at first\n",
    "    codeset.insert(0, 'Info', ll2)\n",
    "\n",
    "    # Apply strip to the 'names' column\n",
    "    codeset['Info'] = codeset['Info'].str.strip()\n",
    "    \n",
    "    # Extracting rows with 'Resource Name'\n",
    "    pattern = 'Resource'\n",
    "\n",
    "    cod = data5[data5['Activity ID'].str.contains(pattern)]\n",
    "\n",
    "    # Creating new column named 'Resource Name' by replacing Resource name from col 'Activity ID'\n",
    "    cod['Info'] = cod['Activity ID'].str.replace('Resource Name: ', '')\n",
    "\n",
    "    # Dropping unwanted columns\n",
    "    codes = cod.drop('Activity ID', axis = 1)\n",
    "    codes = codes.reset_index()\n",
    "\n",
    "    codes = codes.drop(['index'], axis = 1)\n",
    "\n",
    "    lo2 = codes.pop('Info')\n",
    "\n",
    "    # Placing the pop up column at first\n",
    "    codes.insert(0, 'Info', lo2)\n",
    "\n",
    "    # Apply strip to the 'names' column\n",
    "    codes['Info'] = codes['Info'].str.strip()\n",
    "    \n",
    "    # List of missing resource name (not in rft)\n",
    "    cs = list(codes['Info'].unique())\n",
    "    cs = [i.strip() for i in cs]\n",
    "\n",
    "    # Select p6 resource from rft for 'Employee code and UT'\n",
    "    rft1 = rft_report[rft_report['Employee_code'].isin(unique_resource)]\n",
    "\n",
    "    # Get unique list of code and ut for resource in p6\n",
    "    rft2 = rft1[['Resource_Name', 'Employee_code', 'Utilization_Target']].drop_duplicates()\n",
    "    rft2 = rft2.reset_index()\n",
    "\n",
    "    # Dropping unwanted columns\n",
    "    rft3 = rft2.drop(['index'], axis = 1)\n",
    "\n",
    "    # Merging data7 & rft3 for 'Employee_code' & 'Utilization_Target'\n",
    "    merged_df = pd.merge(data7, rft3, on = 'Employee_code', how = 'right')\n",
    "\n",
    "    # Popping the column to change the position\n",
    "    vll1 = merged_df.pop('Utilization_Target')\n",
    "    vll2 = merged_df.pop('Resource_Name')\n",
    "\n",
    "    # Placing the pop up column at first\n",
    "    merged_df.insert(1, 'Utilization_Target', vll1)\n",
    "    # Placing the pop up column at first\n",
    "    merged_df.insert(0, 'Resource_Name', vll2)\n",
    "\n",
    "    # To replace dash (-) & NaN with Zero (0)\n",
    "    except_col = ['Resource_Name', 'Employee_code', 'Utilization_Target Name']\n",
    "    for column in merged_df.columns:\n",
    "        if column not in except_col:\n",
    "            #data9[column] = data9[column].replace('-', 0)\n",
    "            merged_df[column] = merged_df[column].replace(np.NaN, 0)\n",
    "\n",
    "    # Convert data types for columns except the excluded ones\n",
    "    exclude_columns = ['Resource_Name', 'Employee_code', 'Utilization_Target Name']\n",
    "    for column in merged_df.columns:\n",
    "        if column not in exclude_columns:\n",
    "            merged_df[column] = pd.to_numeric(merged_df[column], errors='coerce')  # You can use other conversion functions if needed\n",
    "    \n",
    "    # Popping the column to change the position\n",
    "    cal1 = ut.pop('Utilization_Target')\n",
    "    cal2 = ut.pop('Employee_code')\n",
    "    cal3 = ut.pop('Resource_Name')\n",
    "\n",
    "   # Placing the pop up column at first\n",
    "    ut.insert(1, 'Utilization_Target', cal1)\n",
    "    # Placing the pop up column at first\n",
    "    ut.insert(1, 'Employee_code', cal2)\n",
    "    # Placing the pop up column at first\n",
    "    ut.insert(1, 'Resource_Name', cal3)\n",
    "    ut = ut.drop('Utilization_Target_percent', axis = 1)\n",
    "\n",
    "    ## Select specific uts\n",
    "    sel = ut[ut['Employee_code'].isin(unique_resource)]\n",
    "\n",
    "    # Ut with only combine columns\n",
    "    ut_com = sel[merged_df.columns]\n",
    "\n",
    "    # RESET INDEX\n",
    "    ut_com = ut_com.reset_index(drop = True)\n",
    "\n",
    "    # Groupby RFT_REPORT based on 'Resource Name' & 'Project Number'\n",
    "    grouped = rft_report.groupby(['Resource_Name', 'Employee_code', 'Utilization_Target','Project Number']).sum()\n",
    "\n",
    "    # Redexing to apply filter on 'Resource Name'\n",
    "    grouped_rft = grouped.reset_index()\n",
    "\n",
    "    # P6 in RFT\n",
    "    set1 = grouped_rft[grouped_rft['Employee_code'].isin(unique_resource)]\n",
    "\n",
    "    # Selecting rft based on Project number not in final_p6 (NOT EXIST/EXIST CASE)\n",
    "    set2 = set1[~set1['Project Number'].isin(pn_list)]\n",
    "\n",
    "    # set2 with only merged_df columns ---index issue\n",
    "    set2 = set2[merged_df.columns]\n",
    "\n",
    "    # Groupby RFT_REPORT based on 'Resource Name' & 'Project Number'\n",
    "    set3 = set2.groupby(['Resource_Name', 'Employee_code', 'Utilization_Target']).sum()\n",
    "    set3 = set3.reset_index()\n",
    "\n",
    "    ## 1. Conbine data9 and set3\n",
    "    combine = merged_df.set_index(['Resource_Name','Employee_code','Utilization_Target']).add(set3.set_index(['Resource_Name','Employee_code','Utilization_Target']), fill_value = 0.0).reset_index()\n",
    "    \n",
    "    # List of unique Resource Name in p6 data\n",
    "    listrft = list(combine['Employee_code'].unique())\n",
    "    listrft = [i.strip() for i in listrft]\n",
    "    combine1 = ut_com.set_index(['Resource_Name','Employee_code','Utilization_Target']).subtract(combine.set_index(['Resource_Name','Employee_code','Utilization_Target']), fill_value=0).reset_index()\n",
    "\n",
    "    # List of missing resource name (not in rft)\n",
    "    resource = list(combine1['Employee_code'].unique())\n",
    "    resource = [i.strip() for i in resource]\n",
    "\n",
    "    # Not in rft\n",
    "    missing_resource = set(unique_resource) - set(resource)\n",
    "    miss_df = data7[data7['Employee_code'].isin(missing_resource)]\n",
    "    \n",
    "    match = {'Resource_Name': [],\n",
    "         'Employee_code': [] }\n",
    "\n",
    "    for idx, i in enumerate(missing_resource):\n",
    "        # Use isin() to find the matching row index\n",
    "        matching_index = codeset[codeset['Info'].isin([i])].index\n",
    "\n",
    "        try:\n",
    "            # Extract the row immediately following the matching index\n",
    "            if not matching_index.empty:\n",
    "                following_row_index = matching_index[0] - 1      # code row\n",
    "                following_row = codeset.iloc[following_row_index]   # code numer\n",
    "\n",
    "                match['Employee_code'].append(codeset.iloc[matching_index[0]]['Info'])\n",
    "                match['Resource_Name'].append(following_row['Info'])\n",
    "            else:\n",
    "                continue\n",
    "        except IndexError:\n",
    "            match['Employee_code'].append(i)\n",
    "            match['Resource_Name'].append('-')\n",
    "            \n",
    "    df = pd.DataFrame(match)\n",
    "    # Merge DataFrames based on the 'ID' column\n",
    "    missdf = pd.merge(df, miss_df, on='Employee_code', how='inner')\n",
    "    \n",
    "    # Merging data7 & rft3 for 'Employee_code' & 'Utilization_Target'\n",
    "    combb = pd.concat([combine1, missdf], axis = 0)\n",
    "    combb['Utilization_Target'] = combb['Utilization_Target'].astype(str)\n",
    "    combb['Employee_code'] = combb['Employee_code'].astype(str)\n",
    "    \n",
    "    # List of missing resource name (not in rft)\n",
    "    cm = list(combb['Resource_Name'].unique())\n",
    "    cm = [i.strip() for i in cm]\n",
    "\n",
    "    # # Not in rft\n",
    "    rd = set(cs) - set(cm)\n",
    "    result = codes[codes['Info'].isin(rd)]\n",
    "\n",
    "    # Dictionary to map old column names to new column names\n",
    "    new_columns = {'Info': 'Resource_Name'}\n",
    "\n",
    "    # Rename columns using the 'rename' method\n",
    "    result = result.rename(columns=new_columns)\n",
    "    \n",
    "    # Merging data7 & rft3 for 'Employee_code' & 'Utilization_Target'\n",
    "    mrg = pd.concat([missdf, result], axis = 0)\n",
    "     \n",
    "    # Add '*' after each value in columns 'A' and 'B'\n",
    "    mrg['Resource_Name'] = mrg['Resource_Name'].astype(str) + '*'\n",
    "    \n",
    "    # Merging data7 & rft3 for 'Employee_code' & 'Utilization_Target'\n",
    "    comb = pd.concat([combine1, mrg], axis = 0)\n",
    "    comb['Utilization_Target'] = comb['Utilization_Target'].astype(str)\n",
    "    comb['Employee_code'] = comb['Employee_code'].astype(str)\n",
    "\n",
    "    # To replace dash (-) & NaN with Zero (0)\n",
    "    except_col = ['Employee_code', 'Utilization_Target']\n",
    "    for column in comb.columns:\n",
    "        if column in except_col:\n",
    "            #data9[column] = data9[column].replace('-', 0)\n",
    "            comb[column] = comb[column].replace('nan', '-')\n",
    "    comb=comb.round(0)\n",
    "    comb = comb.reset_index()\n",
    "    comb = comb.drop('index', axis=1)\n",
    "\n",
    "    def highlight_max(cell_value):\n",
    "        highlight = 'background-color: tomato;'\n",
    "        color = 'background-color: lightblue;'\n",
    "        default = ''\n",
    "        if type(cell_value) in [float]:\n",
    "            if cell_value < 0:\n",
    "                return highlight\n",
    "            else:\n",
    "                return color\n",
    "        else:\n",
    "            if '*' in cell_value:\n",
    "                return 'color:red'\n",
    "        return default\n",
    "\n",
    "    # # Apply the custom styling to the entire DataFrame\n",
    "    # # Apply color to combine\n",
    "    final_data = comb.style.applymap(highlight_max).format(precision = 0)\n",
    "    final_data\n",
    "\n",
    "\n",
    "    # Apply color to combine\n",
    "    final_data = comb.style.applymap(highlight_max).format(precision = 0)\n",
    "    test = comb.copy()\n",
    "\n",
    "    # AVAILABLE RESOURCES\n",
    "    test = test[(test[test.columns[3:]] >= 0).all(axis=1)]\n",
    "    pos_resources = test['Resource_Name'].unique()\n",
    "\n",
    "    # Selecting pos_resources from arr\n",
    "    neg_info = combine1[~combine1['Employee_code'].isin(pos_resources)]\n",
    "    neg_info = neg_info.reset_index(drop=True)\n",
    "\n",
    "    # Calling from rft: set3\n",
    "    rft_set4 = set3[set3['Employee_code'].isin(neg_info['Employee_code'].unique())].reset_index(drop=True)\n",
    "\n",
    "    # Calling from p6: data9\n",
    "    data10 = merged_df[merged_df['Employee_code'].isin(neg_info['Employee_code'].unique())].reset_index(drop=True)\n",
    "    data10 = data10.sort_values(by = 'Employee_code')\n",
    "\n",
    "    # Calling from ut: ut_com\n",
    "    ut1 = ut_com[ut_com['Employee_code'].isin(neg_info['Employee_code'].unique())].reset_index(drop=True)\n",
    "\n",
    "    ## 1. Combine data10 and rft_set4\n",
    "    av_hours = ut1.set_index(['Resource_Name','Employee_code','Utilization_Target']).subtract(rft_set4.set_index(['Resource_Name','Employee_code','Utilization_Target']), fill_value=0).reset_index()\n",
    "    av_hours = av_hours.sort_values(by = 'Employee_code')\n",
    "\n",
    "    # Compare av_hours & data10\n",
    "    compare = data10.set_index(['Resource_Name']).compare(av_hours.set_index(['Resource_Name']), align_axis = 1).rename(columns={'self': 'P6 Hrs', 'other': 'Avail Hrs'}, level=1).reset_index()\n",
    "\n",
    "    # Replace Nan with 0\n",
    "    compare = compare.replace(np.NaN, 0)\n",
    "    compare=compare.round(0)\n",
    "\n",
    "    # Coloring\n",
    "    def compare_and_color(row):\n",
    "        styles = [''] * len(row)\n",
    "        for i in range(len(compare.columns)-1):\n",
    "            col1 = compare.columns[i]\n",
    "            col2 = compare.columns[i + 1]\n",
    "            if col1[0] == col2[0]:\n",
    "                if row[col1] > row[col2]:\n",
    "                    styles[compare.columns.get_loc(col1)] = 'background-color: pink; color: blue'\n",
    "                    styles[compare.columns.get_loc(col2)] = 'background-color: tomato; color: black'\n",
    "                else:\n",
    "                    styles[compare.columns.get_loc(col1)] = 'background-color: lightblue; color: black'\n",
    "                    styles[compare.columns.get_loc(col2)] = 'background-color: lightblue; color: black'\n",
    "        return styles\n",
    "    styled_df = compare.style.apply(compare_and_color, axis = 1).format(precision = 1)\n",
    "    file_name=temp_folder+\"/Resource Analysis Report-{}-{}.xlsx\".format(email,pn_list[0])\n",
    "    # Saving two dataframes 'final_data' & 'styled_df' in excel file with defined sheet name\n",
    "    with pd.ExcelWriter(file_name) as writer:\n",
    "        final_data.to_excel(writer, sheet_name = 'Summary', index = False)\n",
    "        styled_df.to_excel(writer, sheet_name = 'Overallocated Resources')\n",
    "\n",
    "    # Opening the excel file\n",
    "    workbook = openpyxl.load_workbook(file_name)\n",
    "    worksheet1 = workbook['Summary']\n",
    "    worksheet2 = workbook[\"Overallocated Resources\"]\n",
    "    list1 = data7[~data7['Employee_code'].isin(listrft)]\n",
    "    list2 = list(list1['Employee_code'].unique())\n",
    "    list3 = [i.strip() for i in list2]\n",
    "    worksheet1.cell(row = worksheet1.max_row + 1, column = 1).value = \"\"\n",
    "    x = worksheet1.cell(row = worksheet1.max_row + 1, column = 1)\n",
    "    x.value = '''ATTENTION - Resources not found in RFT'''\n",
    "    x.font = Font(bold = True, color = 'FF5733', italic = False)   # BLACK TEXT - 000000, RED - FF5733, Maroon - 800000\n",
    "    x.fill = PatternFill(start_color = \"FFFFFF\", fill_type = \"solid\")  # off white - FAF9F6, WHITE - FFFFFF\n",
    "    x = worksheet1.cell(row = worksheet1.max_row + 1, column = 1)\n",
    "    x.value = ''' {m} '''.format(m=list3)\n",
    "    x.font = Font(bold = True, color = '000000', italic = True)\n",
    "\n",
    "    # column width\n",
    "    column_widths = {'A': 22, 'B': 16, 'C': 16}\n",
    "    for column, width in column_widths.items():\n",
    "        try:\n",
    "            if column in ['A', 'B', 'C']:\n",
    "                worksheet1.column_dimensions[column].width = width\n",
    "        except:\n",
    "            for column in worksheet1.columns:\n",
    "                adjusted_width = 8\n",
    "                worksheet1.column_dimensions[column[0].column_letter].width = adjusted_width\n",
    "\n",
    "    # Text alignment\n",
    "    max_row = worksheet1.max_row\n",
    "    max_column = worksheet1.max_column\n",
    "    for row in range(1, max_row + 1):\n",
    "        for column in range(1, max_column + 1):\n",
    "            if column != 1:\n",
    "                cell = worksheet1.cell(row = row, column = column)\n",
    "                alignment = Alignment(horizontal = 'center')\n",
    "                cell.alignment = alignment\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # Inserting image\n",
    "    img = Image('OA-note.png')\n",
    "    img.width = 500\n",
    "    img.height = 100\n",
    "    col = \"A\"\n",
    "    row_num = str(len(comb['Employee_code']) + 7)\n",
    "    row_call = col + row_num\n",
    "    img.anchor = row_call\n",
    "    worksheet1.add_image(img)\n",
    "\n",
    "    # Coloring the headers and index\n",
    "    cols_color = PatternFill(patternType='solid', fgColor = Color('D8E4BC') )\n",
    "    rows_color = PatternFill(patternType='solid',fgColor=Color ('FFFFFF') )\n",
    "    for i in range(1,len(comb.columns) + 1):\n",
    "        worksheet1.cell(row = 1, column = i).fill = cols_color\n",
    "    for i in range(2,len(comb.index)+2):\n",
    "        worksheet1.cell(row = i, column = 1).fill = rows_color\n",
    "        worksheet1.cell(row = i, column = 2).fill = rows_color\n",
    "        worksheet1.cell(row = i, column = 3).fill = rows_color\n",
    "\n",
    "    # #### Overallocated Resources\n",
    "    # column width\n",
    "    column_widths = {'B': 20}\n",
    "    for column, width in column_widths.items():\n",
    "        if column in ['B']:\n",
    "            worksheet2.column_dimensions[column].width = width\n",
    "        else: \n",
    "            for column in worksheet2.columns:\n",
    "                adjusted_width = 25\n",
    "                worksheet2.column_dimensions[column[0].column_letter].width = adjusted_width\n",
    "\n",
    "    # Text alignment\n",
    "    max_row = worksheet2.max_row\n",
    "    max_column = worksheet2.max_column\n",
    "    for row in range(1, max_row + 1):\n",
    "        for column in range(1, max_column + 1):\n",
    "            if column != 2:\n",
    "                cell = worksheet2.cell(row = row, column = column)\n",
    "                alignment = Alignment(horizontal = 'center')\n",
    "                cell.alignment = alignment\n",
    "            else:\n",
    "                pass\n",
    "    new_serial_numbers = list(range(1,len(compare['Resource_Name'])+1))  # Replace this with your desired new serial numbers\n",
    "\n",
    "    # Iterate through the rows and update the serial numbers in column A\n",
    "    for i, new_value in enumerate(new_serial_numbers):\n",
    "        row_number = i + 4  # Rows are 1-indexed in Excel\n",
    "        worksheet2.cell(row = row_number, column=1, value=new_value)\n",
    "    worksheet2.column_dimensions['A'].hidden = True\n",
    "    worksheet2.delete_rows(idx=3)   #for rows\n",
    "\n",
    "    # Inserting image\n",
    "    img = Image('color_legend.png')\n",
    "    img.width = 500\n",
    "    img.height = 35\n",
    "    col1 = \"A\"\n",
    "    row_num1 = str(len(compare['Resource_Name']) + 5)\n",
    "    row_call1 = col1 + row_num1\n",
    "    img.anchor = row_call1\n",
    "    worksheet2.add_image(img)\n",
    "\n",
    "    # Inserting image -- \n",
    "    img = Image('Summary-note.png')\n",
    "    img.width = 500\n",
    "    img.height = 150\n",
    "    col2 = \"A\"\n",
    "    row_num2 = str(len(compare['Resource_Name']) + 8)\n",
    "    row_call2 = col2 + row_num2\n",
    "    img.anchor = row_call2\n",
    "    worksheet2.add_image(img)\n",
    "\n",
    "    # Coloring the headers and index\n",
    "    col_color = PatternFill(patternType='solid', fgColor = Color('D8E4BC') )\n",
    "    #row_color = PatternFill(patternType='solid',fgColor=Color ('E0EEEE') )\n",
    "    for i in range(1,len(compare.columns) + 2):\n",
    "        worksheet2.cell(row = 1, column = i).fill = col_color\n",
    "    workbook.save(file_name)\n",
    "    workbook.close()\n",
    "    \n",
    "    l1=pn_list[0]+'-'+email\n",
    "    l2=pn_list[0]+'-'+u_email\n",
    "    l3 = 'No_OA'\n",
    "    excel2img.export_img(file_name, \"static/{}.png\".format(l1), \"Summary\", None)\n",
    "    excel2img.export_img(file_name, \"static/{}.png\".format(l2), \"Overallocated Resources\", None)\n",
    "    excel2img.export_img('No_OA.xlsx', \"static/{}.png\".format(l3), \"Sheet1\", \"A1:B1\")\n",
    "    if compare.empty:\n",
    "        return redirect(url_for('temp_fold', f2=name, temp_folder=temp_folder,l1=l1, l2=l3))\n",
    "    else:\n",
    "        return redirect(url_for('temp_fold', f2=name, temp_folder=temp_folder,l1=l1, l2=l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/temp_fold/<f2>/<temp_folder>/<l1>/<l2>') \n",
    "def temp_fold(f2,temp_folder,l1,l2):\n",
    "    tf=temp_folder\n",
    "    src_path2 = os.getcwd()+\"/\"+f2\n",
    "    dst_path2 = temp_folder+\"/\"+f2\n",
    "    shutil.move(src_path2, dst_path2)\n",
    "    #return redirect('/gallery')\n",
    "    return redirect(url_for('gallery',l1=l1,l2=l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/gallery/<l1>/<l2>') \n",
    "def gallery(l1,l2):\n",
    "    return render_template('gallery.html',l1=l1,l2=l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ownload_file() func. will download 'Resource Analysis Report' excel in internal system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/download', methods=['GET'])\n",
    "def download_file():\n",
    "    return send_file(temp_folder+\"/Resource Analysis Report-{}-{}.xlsx\".format(email_f,pn_list[0]), as_attachment = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ack() function will transfer the control back to 'index.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/go_back', methods = ['GET'])\n",
    "def back():\n",
    "    return render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.57.14.0:5000\n",
      "Press CTRL+C to quit\n",
      "10.57.14.0 - - [27/Dec/2023 16:24:00] \"GET / HTTP/1.1\" 200 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:24:00] \"GET /static/logo.png HTTP/1.1\" 304 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:24:08] \"POST /success HTTP/1.1\" 302 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:25:21] \"GET /external/Book8-nasreenn.xlsx/nasreenn/nasreenn%40cdmsmith.com HTTP/1.1\" 500 -\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\anaconda3\\lib\\site-packages\\excel2img\\excel2img.py\", line 51, in _open\n",
      "    self.app = win32com.client.DispatchEx('Excel.Application')\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\anaconda3\\lib\\site-packages\\win32com\\client\\__init__.py\", line 145, in DispatchEx\n",
      "    dispatch = pythoncom.CoCreateInstanceEx(\n",
      "pywintypes.com_error: (-2146959355, 'Server execution failed', None, None)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2548, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2528, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\Temp\\ipykernel_22312\\2201585069.py\", line 613, in external\n",
      "    excel2img.export_img(file_name, \"static/{}.png\".format(l2), \"Overallocated Resources\", None)\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\anaconda3\\lib\\site-packages\\excel2img\\excel2img.py\", line 84, in export_img\n",
      "    with ExcelFile.open(fn_excel) as excel:\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\anaconda3\\lib\\site-packages\\excel2img\\excel2img.py\", line 28, in open\n",
      "    obj._open(filename)\n",
      "  File \"C:\\Users\\nasreenn\\AppData\\Local\\anaconda3\\lib\\site-packages\\excel2img\\excel2img.py\", line 54, in _open\n",
      "    raise OSError('Failed to start Excel')\n",
      "OSError: Failed to start Excel\n",
      "10.57.14.0 - - [27/Dec/2023 16:25:21] \"GET /external/Book8-nasreenn.xlsx/nasreenn/nasreenn%40cdmsmith.com?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1\" 304 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:25:21] \"GET /external/Book8-nasreenn.xlsx/nasreenn/nasreenn%40cdmsmith.com?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1\" 304 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:25:22] \"GET /external/Book8-nasreenn.xlsx/nasreenn/nasreenn%40cdmsmith.com?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1\" 304 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:27:22] \"GET / HTTP/1.1\" 200 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:27:22] \"GET /static/logo.png HTTP/1.1\" 304 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:27:32] \"POST /success HTTP/1.1\" 302 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:27:51] \"GET /external/Book8-nasreenn.xlsx/nasreenn/nasreenn%40cdmsmith.com HTTP/1.1\" 302 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:27:51] \"GET /temp_fold/Book8-nasreenn.xlsx/C:%5CUsers%5Cnasreenn%5CDocuments%5CCDM%20Projects%5CResource%20Allocation%5Creports/265573-nasreenn/265573-nasreenn%40cdmsmith.com HTTP/1.1\" 302 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:27:51] \"GET /gallery/265573-nasreenn/265573-nasreenn%40cdmsmith.com HTTP/1.1\" 200 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:27:51] \"GET /static/265573-nasreenn@cdmsmith.com.png HTTP/1.1\" 200 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:27:51] \"GET /static/265573-nasreenn.png HTTP/1.1\" 200 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:27:51] \"GET /static/logo.png HTTP/1.1\" 304 -\n",
      "10.57.14.0 - - [27/Dec/2023 16:27:51] \"GET /gallery/265573-nasreenn/static/logo.png HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "app.run(host = \"0.0.0.0\" ,debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
